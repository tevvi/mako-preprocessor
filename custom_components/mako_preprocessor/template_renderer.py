import os
import logging
import traceback
import shutil
from mako.template import Template
from mako.lookup import TemplateLookup
from .run_config import DOMAIN
from .utils import FileMatcher, SerializedParser
from .metadata import MetadataManager
from datetime import datetime, UTC

_LOGGER = logging.getLogger(__name__)

class TemplateRenderer:
    class TrackingUrisLookup(TemplateLookup):
        def __init__(self, *args, **kwargs):
            self.requested_uris = set()
            super().__init__(*args, **kwargs)

        def get_template(self, uri):
            self.requested_uris.add(uri)
            return super().get_template(uri)
        
        def fetch_uris_and_clear(self):
            uris = list(self.requested_uris)
            self.requested_uris.clear()
            return uris

    def __init__(self, run_config):
        _LOGGER.debug("Initializing TemplateRenderer")
        self._batch_active = 0
        if not run_config.is_template_disabled():
            self.lookup = self.TrackingUrisLookup(directories=run_config.directories, input_encoding='utf-8', output_encoding='utf-8')
        else:
            self.lookup = None
        self.run_config = run_config
        self.metadata = MetadataManager()
        self._rendered_files = set()

    def _backup_file(self, file_path):
        if not self.run_config.backup_enabled:
            return

        backup_dir = self.run_config.backup_directory
        if not os.path.exists(backup_dir):
            os.makedirs(backup_dir)
        timestamp = datetime.fromtimestamp(os.path.getmtime(file_path), UTC).strftime('%Y%m%d%H%M%S')
        backup_path = os.path.join(backup_dir, f"{timestamp}_{os.path.basename(file_path)}")
        shutil.move(file_path, backup_path)
        _LOGGER.debug(f"üì¶ Backup created: {backup_path}")

    def _change_file_allowed(self, output_path):
        _LOGGER.debug(f"Checking if file change is allowed: {output_path}")
        if not os.path.exists(output_path):
            return { "allowed": True, "user_changed": False }
        
        
        last_saved = self.metadata.get(output_path)
        if last_saved is None:
            if self.run_config.overwrite_modified_files:
                _LOGGER.warning(f"MAKO-004 ‚ö†Ô∏è File {output_path} was manually modified, but overwriting due to setting.")
                return { "allowed": True, "user_changed": True }
            
            _LOGGER.error(f"MAKO-005 ‚ùå File {output_path} was manually modified! Not overwriting.")
            return { "allowed": False, "user_changed": True }

        last_modified = os.path.getmtime(output_path)
        if last_saved == last_modified:
            return { "allowed": True, "user_changed": False }
        
        if self.run_config.overwrite_modified_files:
            _LOGGER.warning(f"MAKO-004 ‚ö†Ô∏è File {output_path} was manually modified, but overwriting due to setting.")
            return { "allowed": True, "user_changed": True }
        
        _LOGGER.error(f"MAKO-005 ‚ùå File {output_path} was manually modified! Not overwriting.")
        return { "allowed": False, "user_changed": True }

    def format_output(self, rendered_output, template_path, output_path, variables):
        prefix = f"# Generated by: {DOMAIN}\n"
        timestamp = datetime.now(UTC).isoformat()
        prev_timestamp = self.metadata.get(output_path)
        if prev_timestamp:
            prev_timestamp = datetime.fromtimestamp(prev_timestamp, UTC).isoformat()
        metadata_version = self.metadata.version
        postfix = (
            f"\n# Rendered with:\n"
            f"#   variables: {variables}\n"
            f"#   processed from: {template_path}\n"
            f"#   timestamp: {timestamp}\n"
            f"#   prev_timestamp: {prev_timestamp}\n"
            f"#   version: {self.run_config.version}\n"
            f"#   metadata_version: {metadata_version}\n"
        )
        return f"{prefix}{rendered_output}{postfix}"

    def _render(self, template_path, output_path, **variables):
        _LOGGER.debug(f"Rendering template: {template_path} to {output_path}")
        dependencies = []
        check = self._change_file_allowed(output_path)
        if not check["allowed"]:
            return { "success": False, "dependencies": dependencies }
        try:
            template = Template(filename=template_path, lookup=self.lookup)
            rendered_output = template.render(variables=variables, constants=self.run_config.constants)
            dependencies = self.lookup.fetch_uris_and_clear()
            final_output = self.format_output(rendered_output, template_path, output_path, variables)
            
            if check["user_changed"]:
                self._backup_file(output_path)
            with open(output_path, "w", encoding="utf-8") as f:
                f.write(final_output)
            self.metadata.set(output_path, os.path.getmtime(output_path))
            
            _LOGGER.info(f"‚úÖ {template_path} -> {output_path}")
            return { "success": True, "dependencies": dependencies }
        except Exception as e:
            _LOGGER.error(f"MAKO-006 ‚ùå Error processing {template_path}: {e}\n{traceback.format_exc()}")
            return { "success": False, "dependencies": dependencies }

    def _remove_outdated_files(self, current_generated_files, previous_generated_files):
        for file in previous_generated_files:
            if file not in current_generated_files:
                check = self._change_file_allowed(file)
                if not check["allowed"]:
                    _LOGGER.warning(f"MAKO-016 ‚ö†Ô∏è Outdated file {file} was manually modified and will not be removed.")
                    continue
                try:
                    if check["user_changed"]:
                        self._backup_file(file)
                        
                    os.remove(file)
                    _LOGGER.info(f"üóëÔ∏è Removed outdated file: {file}")
                except OSError as e:
                    _LOGGER.error(f"MAKO-017 ‚ùå Error removing outdated file {file}: {e}")

    def _render_serialize(self, serialize_file_path, matched_ext):
        _LOGGER.debug(f"Rendering serialize file: {serialize_file_path}")
        parsed_data = SerializedParser.parse(serialize_file_path, matched_ext, self.run_config.constants)
        if not parsed_data:
            _LOGGER.error(f"MAKO-007 ‚ùå Failed to get data from {serialize_file_path}.")
            return

        outputs = parsed_data.get("outputs")
        if not outputs:
            _LOGGER.error(f"MAKO-008 ‚ùå File {serialize_file_path} must contain 'outputs' key.")
            return

        default_template = parsed_data.get("template")
        default_variables = parsed_data.get("variables", {})
        base_dir = os.path.dirname(serialize_file_path)
        dependencies = set()
        generated_files = set()
        if "dependencies" in parsed_data:
            dependencies.update(parsed_data["dependencies"])

        for output in outputs:
            if "dependencies" in output:
                dependencies.update(output["dependencies"])

            tmpl = output.get("template", default_template)
            if not tmpl:
                _LOGGER.error(
                    f"MAKO-009 ‚ùå No template specified for file {serialize_file_path} either by default or in output. Skipping output {output}."
                )
                continue
            merged_vars = {}
            merged_vars.update(default_variables)
            if "variables" in output:
                merged_vars.update(output["variables"])
            template_path = os.path.join(base_dir, tmpl)
            dependencies.add(template_path)
            if not os.path.exists(template_path):
                _LOGGER.error(
                    f"MAKO-010 ‚ùå Template {template_path} not found for file {serialize_file_path}. Skipping output {output}."
                )
                continue
            output_filename = os.path.join(base_dir, output.get("filename"))
            result = self._render(template_path, output_filename, **merged_vars)
            if result["success"]:
                dependencies.update(result["dependencies"])
                generated_files.add(output_filename)
        
        previous_generated_files = set(self.metadata.get_generated_files(serialize_file_path))
        self._remove_outdated_files(generated_files, previous_generated_files)
        
        self.metadata.set(serialize_file_path, os.path.getmtime(serialize_file_path))
        self.metadata.update_dependencies(serialize_file_path, dependencies)
        self.metadata.set_generated_files(serialize_file_path, generated_files)

    def _process_file(self, file_path):
        _LOGGER.debug(f"Processing file: {file_path}")
        if file_path in self._rendered_files:
            _LOGGER.debug(f"File {file_path} already rendered in this batch. Skipping.")
            return True

        if not os.path.exists(file_path):
            _LOGGER.debug(f"File {file_path} does not exist. Removing metadata.")
            self.metadata.remove_file_metadata(file_path)
            return True
        
        file_type, ext = FileMatcher.get_file_type(file_path, self.run_config)
        
        try:
            if file_type == "render":
                output_path = file_path[:-len(ext)]
                result = self._render(file_path, output_path)
                if not result["success"]:
                    return False
                
                previous_generated_files = set(self.metadata.get_generated_files(file_path))
                current_generated_files = {output_path}
                self._remove_outdated_files(current_generated_files, previous_generated_files)
                
                self.metadata.set(file_path, os.path.getmtime(file_path))
                self.metadata.update_dependencies(file_path, result["dependencies"])
                self.metadata.set_generated_files(file_path, current_generated_files)
                return True
            elif file_type == "serialize":
                return self._render_serialize(file_path, ext)
            if self._batch_active > 0:
                self._rendered_files.add(file_path)
            return False
        except Exception as e:
            _LOGGER.error(f"MAKO-011 ‚ùå Error processing {file_path}: {e}\n{traceback.format_exc()}")
            return False

    def _process_file_and_deps(self, file_path):
        _LOGGER.debug(f"Processing file and dependencies: {file_path}")
        dependents = self.metadata.get_dependents(file_path)
        if not dependents:
            return self._process_file(file_path)
        
        for dep in dependents:
            self._process_file(dep)

    def process_batch(self, files):
        _LOGGER.debug(f"Processing batch of files: {files}")
        self._batch_active += 1
        try:
            with self.metadata.batch_update():
                for file_path in files:
                    self._process_file_and_deps(file_path)
        finally:
            self._batch_active -= 1
            if self._batch_active == 0 and self._rendered_files:
                self._rendered_files.clear()
            _LOGGER.debug(f"Batch update finished, level: {self._batch_active}")
